{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'metabci'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDuan_code\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMetaBCI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMetaBCI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetabci\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbrainda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Wang2016\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetabci\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbrainda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparadigms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SSVEP\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetabci\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbrainda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     set_random_seeds, \n\u001b[1;32m     17\u001b[0m     generate_loo_indices, match_loo_indices)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'metabci'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Authors: Duan Shunguo<dsg@tju.edu.cn>\n",
    "# Date: 2024/9/1\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from scipy.signal import sosfiltfilt\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import sys\n",
    "sys.path.append(r\"D:\\Duan_code\\MetaBCI\\MetaBCI\")\n",
    "from metabci.brainda.datasets import Wang2016\n",
    "from metabci.brainda.paradigms import SSVEP\n",
    "from metabci.brainda.algorithms.utils.model_selection import (\n",
    "    set_random_seeds, \n",
    "    generate_loo_indices, match_loo_indices)\n",
    "from metabci.brainda.algorithms.decomposition import (\n",
    "    FBTRCA, FBTDCA, FBSCCA, FBECCA, FBDSP,\n",
    "    generate_filterbank, generate_cca_references)\n",
    "from metabci.brainda.algorithms.utils.model_selection import (\n",
    "    EnhancedLeaveOneGroupOut)\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import quad, trapz\n",
    "from algorithm.Bayes import Bayes\n",
    "from algorithm import analyze\n",
    "dataset = Wang2016()\n",
    "delay = 0.14 # seconds\n",
    "channels = ['PZ', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'O1', 'OZ', 'O2']\n",
    "srate = 250 # Hz\n",
    "\n",
    "n_bands = 3\n",
    "n_harmonics = 5\n",
    "events = sorted(list(dataset.events.keys()))\n",
    "freqs = [dataset.get_freq(event) for event in events]\n",
    "phases = [dataset.get_phase(event) for event in events]\n",
    "\n",
    "start_pnt = dataset.events[events[0]][1][0]\n",
    "\n",
    "paradigm = SSVEP(\n",
    "    srate=srate, \n",
    "    channels=channels, \n",
    "    # intervals=[(start_pnt+delay, start_pnt+delay+duration+0.1)], # more seconds for TDCA \n",
    "    events=events)\n",
    "\n",
    "wp = [[8*i, 90] for i in range(1, n_bands+1)]\n",
    "ws = [[8*i-2, 95] for i in range(1, n_bands+1)]\n",
    "filterbank = generate_filterbank(\n",
    "    wp, ws, srate, order=4, rp=1)\n",
    "filterweights = np.arange(1, len(filterbank)+1)**(-1.25) + 0.25\n",
    "\n",
    "def data_hook(X, y, meta, caches):\n",
    "    filterbank = generate_filterbank(\n",
    "        [[8, 90]], [[6, 95]], srate, order=4, rp=1)\n",
    "    X = sosfiltfilt(filterbank[0], X, axis=-1)\n",
    "    return X, y, meta, caches\n",
    "\n",
    "paradigm.register_data_hook(data_hook)\n",
    "\n",
    "set_random_seeds(64)\n",
    "l = 5\n",
    "models = OrderedDict([\n",
    "    # ('fbscca', FBSCCA(\n",
    "    #         filterbank, filterweights=filterweights)),\n",
    "    # ('fbecca', FBECCA(\n",
    "    #         filterbank, filterweights=filterweights)),\n",
    "    # ('fbdsp', FBDSP(\n",
    "    #         filterbank, filterweights=filterweights)),\n",
    "    ('fbtrca', FBTRCA(\n",
    "            filterbank, filterweights=filterweights)),\n",
    "    # ('fbtdca', FBTDCA(\n",
    "    #         filterbank, l, n_components=8, \n",
    "    #         filterweights=filterweights)),\n",
    "])\n",
    "\n",
    "X, y, meta = paradigm.get_data(\n",
    "    dataset,\n",
    "    subjects=[1],\n",
    "    return_concat=True,\n",
    "    n_jobs=1,\n",
    "    verbose=False)\n",
    "\n",
    "loo_indices = generate_loo_indices(meta)\n",
    "        \n",
    "Ds = Bayes(models['fbtrca'])\n",
    "for duration in [0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    duration = duration \n",
    "    print(f\"Train_Duration: {duration}\")\n",
    "    filterX, filterY = np.copy(X[..., int(srate*delay):int(srate*(delay+duration))]), np.copy(y)\n",
    "    filterX = filterX - np.mean(filterX, axis=-1, keepdims=True)\n",
    "  \n",
    "    train_ind, validate_ind, _ = match_loo_indices(\n",
    "        5, meta, loo_indices)\n",
    "    train_ind = np.concatenate([train_ind, validate_ind])\n",
    "\n",
    "    trainX, trainY = filterX[train_ind], filterY[train_ind]\n",
    "    Ds.train(trainX,trainY,duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
